# Cat Species Classification: Exploring Few-Shot, Zero-Shot, and Continual Learning

## Overview

This Google Colab notebook explores various machine learning paradigms for image classification on a custom `cat_species_dataset`. The primary goal is to compare the performance of traditional supervised learning with advanced techniques like few-shot learning, zero-shot learning, and continual learning, using both a pre-trained ResNet50 model and a custom-built Convolutional Neural Network (CustomCNN).

The notebook demonstrates:

1.  **Dataset Preparation**: Loading and splitting the dataset into training and testing sets.
2.  **Standard Supervised Learning**: Training and evaluating a ResNet50 and a CustomCNN from scratch.
3.  **Few-Shot Learning**: Adapting models to classify new classes with very few training examples.
4.  **Zero-Shot Learning**: Classifying images into categories not seen during training, based on learned feature similarities.
5.  **Continual Learning**: Training models incrementally on new tasks while mitigating catastrophic forgetting of previous tasks.

## Dataset

The `cat_species_dataset` consists of **420 images** spread across **42 distinct cat species**. Each species generally has around 10 images. The dataset was split into:

*   **Training Samples**: 336 (80%)
*   **Testing Samples**: 84 (20%)

## Methodologies and Key Results

### 1. Standard ResNet Classification (Pre-trained on ImageNet)

*   **Approach**: Loaded a pre-trained ResNet50 model, replaced its final classification layer, and fine-tuned the entire model on the training set.
*   **Training Accuracy (15 Epochs)**: 91.37%
*   **Test Accuracy**: **30.95%**
*   **Observation**: Significant overfitting, indicating that fine-tuning all layers of a large model on a small dataset leads to poor generalization.

### 2. Few-Shot Learning with ResNet

*   **Approach**: Froze the feature extraction layers of a new ResNet50 and trained only the final classification layer on a few-shot dataset (5 samples per class, 210 total samples).
*   **Few-Shot Training Accuracy (10 Epochs)**: 92.86%
*   **Test Accuracy**: **86.90%**
*   **Observation**: Dramatically improved generalization, showcasing the power of transferable features from pre-trained models even with minimal new data.

### 3. Zero-Shot Learning with ResNet

*   **Approach**: Used a new ResNet50 as a fixed feature extractor. Class prototypes were generated by averaging features for each class from the full dataset. Classification was based on cosine similarity.
*   **Test Accuracy**: **89.29%**
*   **Observation**: Achieved the highest accuracy, demonstrating that pre-trained models learn highly discriminative features enabling classification without any explicit task-specific training.

### 4. Continual Learning with ResNet

*   **Approach**: Divided classes into 21 'old' and 21 'new' sets. Trained on 'old' classes, then incrementally on 'new' classes with a replay mechanism (2 samples per old class) to combat forgetting.
*   **Old Task Training Accuracy (5 Epochs)**: 87.14%
*   **Continual Training Accuracy (10 Epochs, New + Replay)**: 96.63%
*   **Final Test Accuracy**: **64.29%**
*   **Observation**: Balanced performance, effectively learning new tasks while retaining knowledge from old ones, outperforming standard ResNet but not few-shot/zero-shot.

### 5. Custom CNN (Trained from Scratch)

*   **Approach**: Designed and trained a CustomCNN model from scratch on the full training dataset.
*   **Training Accuracy (15 Epochs)**: 95.24%
*   **Test Accuracy**: **4.76%**
*   **Observation**: Severe overfitting, performing very poorly on unseen data. This highlights the challenge of training complex models on small datasets without pre-training.

### 6. Few-Shot Learning with Custom CNN

*   **Approach**: Froze the feature layers of a new CustomCNN and trained only its classification head on a few-shot dataset (5 samples per class).
*   **Few-Shot Training Accuracy (10 Epochs)**: 24.76%
*   **Test Accuracy**: **30.95%**
*   **Observation**: Some improvement over standard CustomCNN, but its learned features are less effective than those of a pre-trained ResNet in few-shot settings.

### 7. Zero-Shot Learning with Custom CNN

*   **Approach**: Used a new CustomCNN as a fixed feature extractor, generated class prototypes, and classified based on cosine similarity.
*   **Test Accuracy**: **85.71%**
*   **Observation**: Surprisingly strong performance, comparable to the ResNet-based zero-shot model. This indicates the CustomCNN's convolutional layers can extract discriminative features even without extensive pre-training.

### 8. Continual Learning with Custom CNN

*   **Approach**: Divided classes into 'old' and 'new' sets. Trained a new CustomCNN first on 'old' classes, then continually on 'new' classes with replay.
*   **Old Task Training Accuracy (5 Epochs)**: 51.90%
*   **Continual Training Accuracy (10 Epochs, New + Replay)**: 97.02%
*   **Final Test Accuracy**: **61.90%**
*   **Observation**: Achieved respectable performance, demonstrating the CustomCNN's ability to adapt to incremental learning with replay, similar to the ResNet in this paradigm.

## Conclusion & Insights

*   **Pre-trained Models are Superior for Small Datasets**: Few-shot and zero-shot learning with pre-trained ResNet50 models significantly outperformed all other approaches, including CustomCNN models and even standard fine-tuned ResNet. This underscores the immense value of transfer learning when data is limited.
*   **Overfitting is a Major Challenge**: Training complex models (like CustomCNN) from scratch on small datasets inevitably leads to severe overfitting, as evidenced by the low test accuracies.
*   **CustomCNN Feature Extraction**: While the CustomCNN struggled in standard and few-shot classification, its strong performance in zero-shot learning (85.71%) suggests it develops reasonably discriminative features in its convolutional layers, which can be effectively utilized with similarity-based classification.
*   **Continual Learning shows Promise**: Both ResNet and CustomCNN demonstrated effective continual learning capabilities, allowing models to adapt to new information while retaining old knowledge, which is crucial for real-world dynamic environments.

This notebook provides a comprehensive comparison of different learning paradigms, highlighting the trade-offs and best practices for image classification tasks, especially in data-constrained scenarios.
